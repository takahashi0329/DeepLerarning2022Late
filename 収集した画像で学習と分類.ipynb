{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlZW4tDieReZR+OZsKBaJQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takahashi0329/DeepLerarning2022Late/blob/main/%E5%8F%8E%E9%9B%86%E3%81%97%E3%81%9F%E7%94%BB%E5%83%8F%E3%81%A7%E5%AD%A6%E7%BF%92%E3%81%A8%E5%88%86%E9%A1%9E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 収集した画像をColabにUPして学習させ、それをもとに分類させる"
      ],
      "metadata": {
        "id": "RPwkZvySV6VG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ファイルのフォルダを準備する"
      ],
      "metadata": {
        "id": "oY_MioyXWhOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('sample', exist_ok=True) #分類対象の画像のフォルダを作成\n",
        "os.makedirs('output/dog/sample', exist_ok=True) #犬と判定された時の置き場所\n",
        "os.makedirs('output/cat/sample', exist_ok=True) #猫と判定された時の置き場所\n",
        "os.makedirs('img/deep_learning/dog', exist_ok=True) #犬の学習用の収集画像\n",
        "os.makedirs('img/deep_learning/cat', exist_ok=True) #猫の学習用の収集画像"
      ],
      "metadata": {
        "id": "a35bGpYNWLZe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 必要なライブラリをimport"
      ],
      "metadata": {
        "id": "6hhzg5HiYR4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob as glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "iAG1tSR_YQj6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##分類（クラス）の名前をフォルダ名（dog,cat）から引用する"
      ],
      "metadata": {
        "id": "09DHHaAuZjrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"img/deep_learning\" # dogとcatフォルダがある場所\n",
        "folders = os.listdir(path)\n",
        "# 2つのパスからフォルダを抜き出す\n",
        "classes = [f for f in folders if os.path.isdir(os.path.join(path, f))]\n",
        "print(classes)\n",
        "n_classes = len(classes)\n",
        "print(n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqOZjNiTZi0x",
        "outputId": "a668ca10-8916-4b35-eb99-b99b168c2973"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cat', 'dog']\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 画像読み込みリサイズ、整形する"
      ],
      "metadata": {
        "id": "valN8831_LrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像とラベルのための配列\n",
        "X = [] #画像（学習データ用の配列）\n",
        "Y = [] #ラベル（正解の配列）\n",
        "\n",
        "# 画像を読み込みつつリサイズ\n",
        "for label, class_name in enumerate(classes):\n",
        "  files = glob.glob(path + \"/\" + class_name + \"/*jpg\")\n",
        "  for file in files:\n",
        "    img = cv2.imread(file)\n",
        "    img = cv2.resize(img, dsize=(224,224))\n",
        "    X.append(img)\n",
        "    Y.append(label)\n",
        "    # 内部ループ終わり\n",
        "# 外部ループ終わり"
      ],
      "metadata": {
        "id": "b0VowF0Gb0Eo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0～255のビットデータ値を、学習のために0～1に変換(正規化)学習精度を上げる"
      ],
      "metadata": {
        "id": "VJb65dJyE1PW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X) # 配列XをNumpy配列に変換\n",
        "X = X.astype('float32') #小数型に変換\n",
        "X /=255.0\n",
        "# ラベルもnumpyの配列に変換\n",
        "Y = np.array(Y)\n",
        "Y = np_utils.to_categorical(Y, n_classes)"
      ],
      "metadata": {
        "id": "obQUk_XLFKir"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 整形したデータを学習用とテスト検証用にふりわける"
      ],
      "metadata": {
        "id": "kL8yWNmxGO1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データ8割、テスト検証用が2割にわける\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "# 学習データ8割\n",
        "print(X_train.shape)\n",
        "# テストデータ2割\n",
        "print(X_test.shape)\n",
        "# 学習データ8割(正解ラベル)\n",
        "print(Y_train.shape)\n",
        "# テストデータ2割(正解ラベル)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoRUVDrQGFSs",
        "outputId": "00ab88e9-326a-4583-fa1e-a9be03f41847"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 224, 224, 3)\n",
            "(31, 224, 224, 3)\n",
            "(120, 2)\n",
            "(31, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備したデータを学習させていく"
      ],
      "metadata": {
        "id": "oXZtR1yjLd4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###学習に必要なライブラリをimport"
      ],
      "metadata": {
        "id": "5W0PaU-hLopC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Activation, Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "whtTKrR0HWMm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##モデルのVGG16をアレンジしていく"
      ],
      "metadata": {
        "id": "NLuhpUzyU33t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16 入力層を用意する（定義する）\n",
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "# VGG16のインスタンスを作る（最後のsofmaxの1000層を無効にして省く）\n",
        "base_model = VGG16(weights='imagenet', input_tensor=input_tensor, include_top=False)"
      ],
      "metadata": {
        "id": "tL6aXV7cM6tG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da9e46f5-151f-4908-ffc7-d9b361a630ee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1000分類のsoftmaxを外した代わりに、2つに分類するsoftmax層を追加する"
      ],
      "metadata": {
        "id": "67Hg4PtnWglm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 追加する層の作成\n",
        "top_model = Sequential() #ラッピングする層\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(n_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "yuu7qSAKWZRw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###最後のSOFTMAXを外したモデル(basemodel)と追加用の2つに分類するSOFTMAX層のモデル(top_model)を繋げる"
      ],
      "metadata": {
        "id": "sk9xGwg2aR0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=base_model.input, outputs=top_model(base_model.output))"
      ],
      "metadata": {
        "id": "FwHtOHJNXlsK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###時間短縮のために、15層まで外す"
      ],
      "metadata": {
        "id": "7jIeEqYlcHcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ループしながら15層までを無効にする\n",
        "for layer in model.layers[:15]:\n",
        "  layer.trainable = False #15層までは学習しない\n",
        "#ループ終わり\n",
        "print('# laers=', len(model.layers)) #モデルの層を表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1IyOEwDcGeF",
        "outputId": "225ba961-d03f-4bd2-d19f-647738a94622"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# laers= 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##学習モデルをコンパイルする"
      ],
      "metadata": {
        "id": "YrG0NgMVc-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失はクロスエントロピー法で算出、最適化はADAM、指標は精度でみる\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6Qb5cnTrc9Fu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fGXs7r2eSpy",
        "outputId": "06ceb6e3-4212-4d49-a30b-66d2fed19a87"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 2)                 50178     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,764,866\n",
            "Trainable params: 7,129,602\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## コンパイルしたモデルで収集した画像データを学習させる"
      ],
      "metadata": {
        "id": "LMEPmq0jflqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,Y_train,epochs=20,batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOlt-Purevct",
        "outputId": "b4f7afb4-6153-4ad1-ff9d-b3db24cf6a99"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 13s 249ms/step - loss: 1.2520 - accuracy: 0.5333\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 0.8785 - accuracy: 0.5417\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 0.5642 - accuracy: 0.6917\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 0.6899 - accuracy: 0.5333\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 0.6846 - accuracy: 0.5750\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 0.6883 - accuracy: 0.6083\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 0.6240 - accuracy: 0.7167\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 0.5546 - accuracy: 0.8000\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 0.4091 - accuracy: 0.8583\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.3468 - accuracy: 0.8750\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 0.1416 - accuracy: 0.9750\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.2041 - accuracy: 0.9333\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 0.3129 - accuracy: 0.8667\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 0.4512 - accuracy: 0.8250\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 0.0686 - accuracy: 0.9500\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 0.0835 - accuracy: 0.9667\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 0.0428 - accuracy: 0.9833\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 0.0364 - accuracy: 0.9833\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.0603 - accuracy: 0.9917\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6bd427f070>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##学習の成果を指標(accuracy)で確認"
      ],
      "metadata": {
        "id": "_UNBS9nAhxK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test, batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIZLxoMMhBcI",
        "outputId": "2802f480-38a9-435b-f691-5d03fc361354"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 2s/step - loss: 2.8237 - accuracy: 0.6452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 作成した学習モデルとクラス分類名を保存"
      ],
      "metadata": {
        "id": "qBdgHQNXifoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# vクラス分類の保存\n",
        "pickle.dump(classes, open('classes.sav', 'wb')) # オブジェクトをバイナリファイルで保存\n",
        "# 学習モデル保存\n",
        "model.save('cnn.h5')"
      ],
      "metadata": {
        "id": "2GewROxOiyZ1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##保存したクラス分類と学習モデルを読み込んで使う"
      ],
      "metadata": {
        "id": "s1T456swkl6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ライブラリのimport\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "import cv2\n",
        "import glob"
      ],
      "metadata": {
        "id": "TSfXX_UHjgcn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ファイルを読み込んでオブジェクトとしてよみがえらせる"
      ],
      "metadata": {
        "id": "7j9a79GWlYgt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ha1IvYrmlV4t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}